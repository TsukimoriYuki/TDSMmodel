{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8FkhggHC4B1"
      },
      "source": [
        "# TDSM v2 — Colab(T4)（UNSWテストしか無いときの自動分割版）\n",
        "- Drive 内に **`UNSW_NB15_testing-set.csv` しか無い**場合でも、これを**層化して train/val を自動生成**します（既存の test はそのまま使用）。\n",
        "- 以後は標準化→PCAベースライン→VIB(8–16D)→早期退出→AutoAttack→可視化→保存までワンパスです。"
      ],
      "id": "k8FkhggHC4B1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5e8e4b0-b99a-4121-86f3-d28413414b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b84e71f-8b32-470e-cd37-929df1072eb5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Aug 30 17:36:24 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "PyTorch: 2.8.0+cu126 | CUDA available: True\n",
            "Python: 3.12.11\n"
          ]
        }
      ],
      "source": [
        "#@title GPU / ランタイム確認\n",
        "!nvidia-smi || true\n",
        "import torch, platform\n",
        "print(\"PyTorch:\", torch.__version__, \"| CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Python:\", platform.python_version())"
      ],
      "id": "c5e8e4b0-b99a-4121-86f3-d28413414b25"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6f93622-33b6-41c3-aa24-006a19f02c78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "579d20b2-cb12-4dee-9d8a-a1be558476ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autoattack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Installed.\n"
          ]
        }
      ],
      "source": [
        "#@title 依存導入（PyTorchはColab既定）\n",
        "!pip -q install scikit-learn pandas pyarrow umap-learn shap tqdm matplotlib seaborn\n",
        "!pip -q install \"git+https://github.com/fra31/auto-attack.git\"\n",
        "print(\"Installed.\")"
      ],
      "id": "f6f93622-33b6-41c3-aa24-006a19f02c78"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "399da659-5ac6-4f60-baac-9ea92c38887f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565939c9-1416-4d11-8212-3dcb71e6548f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'device': 'cuda', 'drive_dir': '/content/drive/MyDrive/tdsm_v2'}\n"
          ]
        }
      ],
      "source": [
        "#@title 設定（乱数・ディレクトリ）\n",
        "import os, random, numpy as np, torch\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DTYPE = torch.float16  # T4はFP16推奨\n",
        "DRIVE_MOUNT = \"/content/drive\"\n",
        "DRIVE_DIR = f\"{DRIVE_MOUNT}/MyDrive/tdsm_v2\"\n",
        "print({\"device\": DEVICE, \"drive_dir\": DRIVE_DIR})"
      ],
      "id": "399da659-5ac6-4f60-baac-9ea92c38887f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aa0bbc7-6f69-4363-b1f7-96a8e922dc3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe5da85-dd41-4c6e-8b1a-03824acb2644"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n",
            "Mounted at: /content/drive\n",
            "Ready: ['data', 'artifacts', 'logs', 'configs']\n"
          ]
        }
      ],
      "source": [
        "#@title Driveマウント（安全な再マウント）\n",
        "from google.colab import drive\n",
        "import os, shutil\n",
        "\n",
        "MNT = \"/content/drive\"\n",
        "try:\n",
        "    drive.flush_and_unmount()\n",
        "except Exception:\n",
        "    pass\n",
        "if os.path.isdir(MNT) and os.listdir(MNT):\n",
        "    shutil.rmtree(MNT)\n",
        "os.makedirs(MNT, exist_ok=True)\n",
        "\n",
        "drive.mount(MNT)\n",
        "print(\"Mounted at:\", MNT)\n",
        "\n",
        "for d in [\"data\", \"artifacts\", \"logs\", \"configs\"]:\n",
        "    os.makedirs(os.path.join(DRIVE_DIR, d), exist_ok=True)\n",
        "print(\"Ready:\", os.listdir(DRIVE_DIR))"
      ],
      "id": "2aa0bbc7-6f69-4363-b1f7-96a8e922dc3b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba47652a-490f-4f66-985a-d261fe9eafb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6def55b-fddb-49f2-e27b-64fe4371fc3a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "候補ディレクトリ: /content/drive/MyDrive\n",
            "train: None\n",
            "val:   None\n",
            "test:  /content/drive/MyDrive/UNSW_NB15_testing-set.csv\n"
          ]
        }
      ],
      "source": [
        "#@title Drive内を探索して train/val/test を検出（.parquet/.csv）\n",
        "import os, json, pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "SEARCH_ROOTS = [\n",
        "    os.path.join(DRIVE_DIR, \"data\"),\n",
        "    DRIVE_DIR,\n",
        "    \"/content/drive/MyDrive\",\n",
        "]\n",
        "ALLOWED_EXTS = (\".parquet\", \".csv\")\n",
        "ROLE_KEYS = {\n",
        "    \"train\": [\"train\", \"training\", \"trn\"],\n",
        "    \"val\":   [\"val\", \"valid\", \"validation\", \"dev\"],\n",
        "    \"test\":  [\"test\", \"tst\", \"eval\"],\n",
        "}\n",
        "\n",
        "def _depth(p, root): return os.path.relpath(p, root).count(os.sep)\n",
        "def _role_from_name(name):\n",
        "    n = name.lower()\n",
        "    for role, keys in ROLE_KEYS.items():\n",
        "        if any(k in n for k in keys):\n",
        "            return role\n",
        "    return None\n",
        "\n",
        "def scan_candidates(root, max_depth=5, max_files=5000):\n",
        "    found = []\n",
        "    seen = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        if _depth(dirpath, root) > max_depth:\n",
        "            continue\n",
        "        for fn in filenames:\n",
        "            seen += 1\n",
        "            if seen > max_files: break\n",
        "            if fn.lower().endswith(ALLOWED_EXTS):\n",
        "                role = _role_from_name(fn)\n",
        "                found.append((role, os.path.join(dirpath, fn)))\n",
        "        if seen > max_files: break\n",
        "    return found\n",
        "\n",
        "buckets = defaultdict(lambda: defaultdict(list))\n",
        "for root in SEARCH_ROOTS:\n",
        "    if not os.path.isdir(root): continue\n",
        "    for role, path in scan_candidates(root):\n",
        "        parent = os.path.dirname(path)\n",
        "        buckets[parent][role].append(path)\n",
        "\n",
        "def score_dir(d):\n",
        "    roles = buckets[d]; have = set(k for k,v in roles.items() if len(v)>0)\n",
        "    base = 0\n",
        "    if \"train\" in have: base += 2\n",
        "    if \"test\"  in have: base += 2\n",
        "    if \"val\"   in have: base += 1\n",
        "    name = d.lower()\n",
        "    if any(k in name for k in [\"unsw\",\"cic\",\"ids\",\"rebuilt\",\"quic\",\"visquic\",\"cesnet\"]):\n",
        "        base += 1\n",
        "    return base\n",
        "\n",
        "candidates = sorted(buckets.keys(), key=score_dir, reverse=True)\n",
        "assert len(candidates) > 0, \"Drive内に .parquet/.csv が見つかりませんでした。\"\n",
        "chosen = candidates[0]; roles = buckets[chosen]\n",
        "def pick_first(role): return sorted(roles.get(role, []))[0] if roles.get(role) else None\n",
        "\n",
        "train_path = pick_first(\"train\")\n",
        "val_path   = pick_first(\"val\")\n",
        "test_path  = pick_first(\"test\")\n",
        "\n",
        "print(\"候補ディレクトリ:\", chosen)\n",
        "print(\"train:\", train_path)\n",
        "print(\"val:  \", val_path)\n",
        "print(\"test: \", test_path)\n",
        "\n",
        "DATA_PATHS = {\"train\": train_path, \"val\": val_path, \"test\": test_path}\n",
        "USE_SYNTHETIC = False\n",
        "\n",
        "# 軽く保存（ログ用）\n",
        "json.dump(DATA_PATHS, open(os.path.join(DRIVE_DIR,\"configs\",\"DATA_PATHS_detected.json\"),\"w\"), indent=2, ensure_ascii=False)"
      ],
      "id": "ba47652a-490f-4f66-985a-d261fe9eafb7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06fade49-1a18-4470-8f67-c70b7f9f87df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6934590e-3195-46e5-b4b4-b2691c7a4d14"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNSWテストのみ検出： /content/drive/MyDrive/UNSW_NB15_testing-set.csv\n",
            "生成しました: /content/drive/MyDrive/auto_train_from_UNSWtest.csv /content/drive/MyDrive/auto_val_from_UNSWtest.csv\n",
            "最終 DATA_PATHS: {'train': '/content/drive/MyDrive/auto_train_from_UNSWtest.csv', 'val': '/content/drive/MyDrive/auto_val_from_UNSWtest.csv', 'test': '/content/drive/MyDrive/UNSW_NB15_testing-set.csv'}\n"
          ]
        }
      ],
      "source": [
        "#@title （UNSW専用）testしか無い場合：UNSW_NB15_testing-set.csv から train/val を自動生成\n",
        "import os, pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "VAL_FRAC = 0.20  # testから val を切り出す割合（train:val=80:20）\n",
        "\n",
        "def _load_df(path):\n",
        "    return pd.read_parquet(path) if path.lower().endswith(\".parquet\") else pd.read_csv(path)\n",
        "\n",
        "def _detect_or_make_label(df):\n",
        "    # 優先順位: label/Label -> class/Class -> attack_cat (Normal=0, else 1)\n",
        "    for cand in [\"label\",\"Label\",\"class\",\"Class\",\"target\",\"Target\",\"y\"]:\n",
        "        if cand in df.columns:\n",
        "            return cand, df[cand]\n",
        "    if \"attack_cat\" in df.columns:\n",
        "        return \"label\", (df[\"attack_cat\"].astype(str).str.lower()!=\"normal\").astype(\"int64\")\n",
        "    raise ValueError(\"ラベル列が見つかりません（label/Label/class/attack_catなど）。\")\n",
        "\n",
        "if DATA_PATHS.get(\"train\") is None and DATA_PATHS.get(\"val\") is None and DATA_PATHS.get(\"test\") is not None:\n",
        "    src = DATA_PATHS[\"test\"]\n",
        "    base = os.path.basename(src).lower()\n",
        "    if \"unsw\" in base and \"testing\" in base:\n",
        "        print(\"UNSWテストのみ検出：\", src)\n",
        "        df = _load_df(src)\n",
        "        # ラベル確認（無ければ attack_cat から作る）\n",
        "        label_col, series = _detect_or_make_label(df)\n",
        "        if label_col != \"label\":\n",
        "            df[\"label\"] = series.values  # 統一\n",
        "            label_col = \"label\"\n",
        "        # stratified split: train/val（testは元ファイルをそのまま使用）\n",
        "        tr, va = train_test_split(df, test_size=VAL_FRAC, random_state=42, stratify=df[label_col])\n",
        "        parent = os.path.dirname(src)\n",
        "        train_out = os.path.join(parent, f\"auto_train_from_UNSWtest.csv\")\n",
        "        val_out   = os.path.join(parent, f\"auto_val_from_UNSWtest.csv\")\n",
        "        tr.to_csv(train_out, index=False); va.to_csv(val_out, index=False)\n",
        "        DATA_PATHS[\"train\"] = train_out\n",
        "        DATA_PATHS[\"val\"]   = val_out\n",
        "        print(\"生成しました:\", train_out, val_out)\n",
        "    else:\n",
        "        print(\"testのみですがUNSWテスト名ではないため自動分割はスキップしました。\")\n",
        "\n",
        "print(\"最終 DATA_PATHS:\", DATA_PATHS)"
      ],
      "id": "06fade49-1a18-4470-8f67-c70b7f9f87df"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b064a6b3-30ac-4a9e-8e26-f8b50ec1cec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "ced7fd42-87ef-4723-8319-778cd918a319"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features: 40 | sample: ['id', 'dur', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate', 'sttl'] ...\n",
            "Shapes: (65865, 45) (16467, 45) (82332, 45) | label: label\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
              "0  46264  1.457374   tcp    http   FIN     10     16     814    9878   \n",
              "1   3575  0.654355   tcp       -   FIN     10      8     564     354   \n",
              "2  43204  0.000002   udp       -   INT      2      0    1064       0   \n",
              "\n",
              "            rate  ...  ct_dst_sport_ltm  ct_dst_src_ltm  is_ftp_login  \\\n",
              "0      17.154142  ...                 1               1             0   \n",
              "1      25.979782  ...                 1               1             0   \n",
              "2  500000.001300  ...                 1              34             0   \n",
              "\n",
              "   ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  is_sm_ips_ports  \\\n",
              "0           0                 1           2           1                0   \n",
              "1           0                 0           1           1                0   \n",
              "2           0                 0          10          33                0   \n",
              "\n",
              "       attack_cat  label  \n",
              "0        Exploits      1  \n",
              "1  Reconnaissance      1  \n",
              "2          Normal      0  \n",
              "\n",
              "[3 rows x 45 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a0b3959-20ec-4c07-b3d6-d1bddc2862d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>dur</th>\n",
              "      <th>proto</th>\n",
              "      <th>service</th>\n",
              "      <th>state</th>\n",
              "      <th>spkts</th>\n",
              "      <th>dpkts</th>\n",
              "      <th>sbytes</th>\n",
              "      <th>dbytes</th>\n",
              "      <th>rate</th>\n",
              "      <th>...</th>\n",
              "      <th>ct_dst_sport_ltm</th>\n",
              "      <th>ct_dst_src_ltm</th>\n",
              "      <th>is_ftp_login</th>\n",
              "      <th>ct_ftp_cmd</th>\n",
              "      <th>ct_flw_http_mthd</th>\n",
              "      <th>ct_src_ltm</th>\n",
              "      <th>ct_srv_dst</th>\n",
              "      <th>is_sm_ips_ports</th>\n",
              "      <th>attack_cat</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>46264</td>\n",
              "      <td>1.457374</td>\n",
              "      <td>tcp</td>\n",
              "      <td>http</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>16</td>\n",
              "      <td>814</td>\n",
              "      <td>9878</td>\n",
              "      <td>17.154142</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Exploits</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3575</td>\n",
              "      <td>0.654355</td>\n",
              "      <td>tcp</td>\n",
              "      <td>-</td>\n",
              "      <td>FIN</td>\n",
              "      <td>10</td>\n",
              "      <td>8</td>\n",
              "      <td>564</td>\n",
              "      <td>354</td>\n",
              "      <td>25.979782</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Reconnaissance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>43204</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>udp</td>\n",
              "      <td>-</td>\n",
              "      <td>INT</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1064</td>\n",
              "      <td>0</td>\n",
              "      <td>500000.001300</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>Normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 45 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a0b3959-20ec-4c07-b3d6-d1bddc2862d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6a0b3959-20ec-4c07-b3d6-d1bddc2862d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6a0b3959-20ec-4c07-b3d6-d1bddc2862d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f5936d79-ca78-4b02-8552-e477e747e97c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f5936d79-ca78-4b02-8552-e477e747e97c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f5936d79-ca78-4b02-8552-e477e747e97c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#@title データローダ（数値特徴だけを自動選択）\n",
        "import pandas as pd, numpy as np, os\n",
        "\n",
        "def load_df(path):\n",
        "    return pd.read_parquet(path) if path.lower().endswith(\".parquet\") else pd.read_csv(path)\n",
        "\n",
        "assert DATA_PATHS[\"train\"] is not None and DATA_PATHS[\"val\"] is not None and DATA_PATHS[\"test\"] is not None,     \"DATA_PATHS が揃っていません（自動分割セルのログを確認してください）。\"\n",
        "\n",
        "df_train, df_val, df_test = (load_df(DATA_PATHS[\"train\"]), load_df(DATA_PATHS[\"val\"]), load_df(DATA_PATHS[\"test\"]))\n",
        "\n",
        "# ラベル列の特定（なければ 'label' を作ることも考慮）\n",
        "def pick_label(df):\n",
        "    for cand in [\"label\",\"Label\",\"class\",\"Class\",\"target\",\"Target\",\"y\"]:\n",
        "        if cand in df.columns: return cand\n",
        "    if \"attack_cat\" in df.columns: return \"attack_cat\"\n",
        "    raise ValueError(\"ラベル列が見つかりません。\")\n",
        "\n",
        "label_col = pick_label(df_train)\n",
        "if label_col != \"label\":\n",
        "    if label_col == \"attack_cat\":\n",
        "        for d in (df_train, df_val, df_test):\n",
        "            d[\"label\"] = (d[\"attack_cat\"].astype(str).str.lower()!=\"normal\").astype(\"int64\")\n",
        "    else:\n",
        "        for d in (df_train, df_val, df_test):\n",
        "            d[\"label\"] = d[label_col].astype(\"int64\")\n",
        "    label_col = \"label\"\n",
        "\n",
        "# 数値列のみを特徴に採用（ポート/フラグ/統計など）\n",
        "num_cols = [c for c in df_train.select_dtypes(include=[np.number]).columns if c != \"label\"]\n",
        "feature_cols = num_cols\n",
        "print(\"features:\", len(feature_cols), \"| sample:\", feature_cols[:8], \"...\")\n",
        "print(\"Shapes:\", df_train.shape, df_val.shape, df_test.shape, \"| label:\", label_col)\n",
        "df_train.head(3)"
      ],
      "id": "b064a6b3-30ac-4a9e-8e26-f8b50ec1cec6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfcd4b0c-0b49-403b-9f4d-c6b814a7f32d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d895cf0-da29-4993-ecc5-69ba1e3a57f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([65865, 40]) torch.Size([65865]) torch.Size([16467, 40]) torch.Size([16467])\n"
          ]
        }
      ],
      "source": [
        "#@title 標準化→Tensor化\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "\n",
        "scaler = StandardScaler().fit(df_train[feature_cols].values)\n",
        "\n",
        "def to_tensors(df):\n",
        "    X = scaler.transform(df[feature_cols].values).astype(\"float32\")\n",
        "    y = df[\"label\"].astype(\"int64\").values\n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "Xtr, ytr = to_tensors(df_train)\n",
        "Xva, yva = to_tensors(df_val)\n",
        "Xte, yte = to_tensors(df_test)\n",
        "\n",
        "print(Xtr.shape, ytr.shape, Xva.shape, yva.shape)"
      ],
      "id": "bfcd4b0c-0b49-403b-9f4d-c6b814a7f32d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "552fe824-2872-4ff3-b019-4518207b076e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62163d5d-3e31-45d7-b3d9-c6c5cda65979"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val AUROC/AUPRC: 0.9846 0.9868\n",
            "Test AUROC/AUPRC: 0.9844 0.9867\n"
          ]
        }
      ],
      "source": [
        "#@title ベースライン（PCA→LogReg）\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "\n",
        "pca = PCA(n_components=min(32, Xtr.shape[1])).fit(Xtr.numpy())\n",
        "Ztr, Zva, Zte = pca.transform(Xtr.numpy()), pca.transform(Xva.numpy()), pca.transform(Xte.numpy())\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000, n_jobs=1).fit(Ztr, ytr.numpy())\n",
        "proba_va = clf.predict_proba(Zva)[:,1]; proba_te = clf.predict_proba(Zte)[:,1]\n",
        "print(\"Val AUROC/AUPRC:\",\n",
        "      round(roc_auc_score(yva.numpy(), proba_va),4),\n",
        "      round(average_precision_score(yva.numpy(), proba_va),4))\n",
        "print(\"Test AUROC/AUPRC:\",\n",
        "      round(roc_auc_score(yte.numpy(), proba_te),4),\n",
        "      round(average_precision_score(yte.numpy(), proba_te),4))"
      ],
      "id": "552fe824-2872-4ff3-b019-4518207b076e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1f313df-249d-494b-bffa-540a30998afa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e0f6cd-0c2c-429a-c15b-30ff5d479bb8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3335009135.py:44: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
            "/tmp/ipython-input-3335009135.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
            "/tmp/ipython-input-3335009135.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP1] val AUROC=0.9872 AP=0.9881 | time=2.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3335009135.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
            "/tmp/ipython-input-3335009135.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
            "/tmp/ipython-input-3335009135.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP2] val AUROC=0.9925 AP=0.9929 | time=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3335009135.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
            "/tmp/ipython-input-3335009135.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP3] val AUROC=0.9961 AP=0.9964 | time=1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3335009135.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
            "/tmp/ipython-input-3335009135.py:66: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP4] val AUROC=0.9974 AP=0.9974 | time=1.0s\n",
            "[EP5] val AUROC=0.9979 AP=0.9979 | time=1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3335009135.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n"
          ]
        }
      ],
      "source": [
        "#@title TDSM-MVP（VIB 8–16D＋早期退出）学習\n",
        "import torch, torch.nn as nn, torch.nn.functional as F, time\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "LATENT_D = 16\n",
        "BATCH = 512\n",
        "EPOCHS = 5\n",
        "BETA = 1e-2\n",
        "DELTA = 0.90\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "val_loader   = DataLoader(TensorDataset(Xva, yva), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "test_loader  = DataLoader(TensorDataset(Xte, yte), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "class VIBNet(nn.Module):\n",
        "    def __init__(self, in_dim, z_dim, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Linear(in_dim, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU())\n",
        "        self.mu = nn.Linear(128, z_dim); self.logvar = nn.Linear(128, z_dim)\n",
        "        self.head_early = nn.Linear(z_dim, n_classes)\n",
        "        self.head_final = nn.Linear(z_dim, n_classes)\n",
        "    def reparam(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar); eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    def forward(self, x, early_threshold=None):\n",
        "        h = self.enc(x)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        logits_early = self.head_early(mu)\n",
        "        if early_threshold is not None:\n",
        "            conf = F.softmax(logits_early, dim=1).max(dim=1).values\n",
        "            use_early = conf >= early_threshold\n",
        "        else:\n",
        "            use_early = torch.zeros(x.size(0), dtype=torch.bool, device=x.device)\n",
        "        z = self.reparam(mu, logvar); logits_final = self.head_final(z)\n",
        "        return logits_early, logits_final, mu, logvar, use_early\n",
        "\n",
        "def vib_loss(logits, y, mu, logvar, beta=BETA):\n",
        "    ce = F.cross_entropy(logits, y)\n",
        "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "    return ce + beta * kl, ce, kl\n",
        "\n",
        "model = VIBNet(in_dim=Xtr.shape[1], z_dim=LATENT_D).to(DEVICE)\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "def evaluate(loader, use_early=True):\n",
        "    model.eval(); all_p, all_y = [], []\n",
        "    with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA if use_early else None)\n",
        "            logits = torch.where(use_e.unsqueeze(1), le, lf)\n",
        "            prob1 = F.softmax(logits, dim=1)[:,1]\n",
        "            all_p.append(prob1.detach().cpu()); all_y.append(yb.cpu())\n",
        "    import numpy as np\n",
        "    p = torch.cat(all_p).numpy(); y = torch.cat(all_y).numpy()\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    return float(roc_auc_score(y, p)), float(average_precision_score(y, p))\n",
        "\n",
        "best = -1.0\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train(); import time; t0=time.time()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
        "            le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA)\n",
        "            loss, ce, kl = vib_loss(lf, yb, mu, logvar, beta=BETA)\n",
        "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "    val_roc, val_ap = evaluate(val_loader, use_early=True)\n",
        "    print(f\"[EP{ep}] val AUROC={val_roc:.4f} AP={val_ap:.4f} | time={time.time()-t0:.1f}s\")\n",
        "    if val_roc > best:\n",
        "        best = val_roc\n",
        "        torch.save(model.state_dict(), os.path.join(DRIVE_DIR,\"artifacts\",\"vib_best.pt\"))"
      ],
      "id": "d1f313df-249d-494b-bffa-540a30998afa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f287b5bb-1f88-4042-8aa9-299813271bd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3aa32c8-a89b-4820-b4b2-8eb73eefacfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1698503753.py:9: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda'), dtype=torch.float16):\n",
            "/tmp/ipython-input-1698503753.py:19: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda'), dtype=torch.float16):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early-Exit: mean 1.15 ms | p95 1.88 ms | exit_ratio 0.00%\n",
            "No-Exit:   mean 1.16 ms | p95 2.18 ms\n"
          ]
        }
      ],
      "source": [
        "#@title 推論レイテンシ & 早期退出\n",
        "import time, numpy as np, torch.nn.functional as F, os, torch\n",
        "model.load_state_dict(torch.load(os.path.join(DRIVE_DIR,\"artifacts\",\"vib_best.pt\"), map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "def latency_test(loader, use_early=True, iters=50):\n",
        "    for xb, yb in loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=(DEVICE=='cuda'), dtype=torch.float16):\n",
        "            _ = model(xb, early_threshold=DELTA if use_early else None)\n",
        "        break\n",
        "    if DEVICE=='cuda': torch.cuda.synchronize()\n",
        "    t=[]; exit_ratio=[]\n",
        "    with torch.no_grad():\n",
        "        for i,(xb,yb) in enumerate(loader):\n",
        "            xb=xb.to(DEVICE)\n",
        "            if DEVICE=='cuda': torch.cuda.synchronize()\n",
        "            t0 = time.time()\n",
        "            with torch.cuda.amp.autocast(enabled=(DEVICE=='cuda'), dtype=torch.float16):\n",
        "                le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA if use_early else None)\n",
        "            if DEVICE=='cuda': torch.cuda.synchronize()\n",
        "            t.append(time.time()-t0)\n",
        "            if use_early: exit_ratio.append(use_e.float().mean().item())\n",
        "            if i>=iters: break\n",
        "    mean_ms = float(np.mean(t)*1000); p95_ms = float(np.percentile(t,95)*1000)\n",
        "    ex = float(np.mean(exit_ratio) if use_early and exit_ratio else 0.0)\n",
        "    return mean_ms, p95_ms, ex\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "test_loader  = DataLoader(TensorDataset(Xte, yte), batch_size=512, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "ms_mean, ms_p95, exit_r = latency_test(test_loader, use_early=True)\n",
        "print(f\"Early-Exit: mean {ms_mean:.2f} ms | p95 {ms_p95:.2f} ms | exit_ratio {exit_r:.2%}\")\n",
        "ms_mean2, ms_p952, _ = latency_test(test_loader, use_early=False)\n",
        "print(f\"No-Exit:   mean {ms_mean2:.2f} ms | p95 {ms_p952:.2f} ms\")"
      ],
      "id": "f287b5bb-1f88-4042-8aa9-299813271bd8"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title AutoAttack（tabular/2値向け：APGD-CEのみ）\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from autoattack import AutoAttack\n",
        "\n",
        "model.eval()\n",
        "\n",
        "# 決定論ラッパー：サンプリングなし（μ→head_early）\n",
        "class DetWrapper(nn.Module):\n",
        "    def __init__(self, mdl):\n",
        "        super().__init__(); self.mdl = mdl\n",
        "    def forward(self, x):\n",
        "        h  = self.mdl.enc(x)\n",
        "        mu = self.mdl.mu(h)\n",
        "        return self.mdl.head_early(mu)\n",
        "\n",
        "wrp = DetWrapper(model).to(DEVICE).eval()\n",
        "\n",
        "Xaa, yaa = Xte.to(DEVICE), yte.to(DEVICE)\n",
        "\n",
        "# APGD-CE のみ（tabular/2値向け）\n",
        "adversary = AutoAttack(wrp, norm='L2', eps=0.25, version='custom')\n",
        "adversary.attacks_to_run = ['apgd-ce']\n",
        "adversary.seed = 0  # 再現性\n",
        "# 速度/厳しさの好みに応じて\n",
        "adversary.apgd.n_iter = 100\n",
        "adversary.apgd.n_restarts = 1\n",
        "\n",
        "# クリーン精度\n",
        "with torch.no_grad():\n",
        "    clean_pred = torch.softmax(wrp(Xaa),1).argmax(1)\n",
        "clean_acc = (clean_pred==yaa).float().mean().item()\n",
        "\n",
        "# 逆例生成（ここはno_gradにしない）\n",
        "x_adv = adversary.run_standard_evaluation(Xaa, yaa, bs=256)\n",
        "\n",
        "# ロバスト精度\n",
        "with torch.no_grad():\n",
        "    adv_pred = torch.softmax(wrp(x_adv),1).argmax(1)\n",
        "robust_acc = (adv_pred==yaa).float().mean().item()\n",
        "\n",
        "print({\"clean_acc\": round(clean_acc,4), \"robust_acc\": round(robust_acc,4)})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TesFNUWgI-WC",
        "outputId": "0d446852-b537-4498-9dc0-3bab0b7d6a79"
      },
      "id": "TesFNUWgI-WC",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using custom version including apgd-ce.\n",
            "initial accuracy: 98.68%\n",
            "apgd-ce - 1/318 - 121 out of 256 successfully perturbed\n",
            "apgd-ce - 2/318 - 175 out of 256 successfully perturbed\n",
            "apgd-ce - 3/318 - 212 out of 256 successfully perturbed\n",
            "apgd-ce - 4/318 - 199 out of 256 successfully perturbed\n",
            "apgd-ce - 5/318 - 195 out of 256 successfully perturbed\n",
            "apgd-ce - 6/318 - 198 out of 256 successfully perturbed\n",
            "apgd-ce - 7/318 - 191 out of 256 successfully perturbed\n",
            "apgd-ce - 8/318 - 197 out of 256 successfully perturbed\n",
            "apgd-ce - 9/318 - 211 out of 256 successfully perturbed\n",
            "apgd-ce - 10/318 - 213 out of 256 successfully perturbed\n",
            "apgd-ce - 11/318 - 190 out of 256 successfully perturbed\n",
            "apgd-ce - 12/318 - 214 out of 256 successfully perturbed\n",
            "apgd-ce - 13/318 - 221 out of 256 successfully perturbed\n",
            "apgd-ce - 14/318 - 220 out of 256 successfully perturbed\n",
            "apgd-ce - 15/318 - 227 out of 256 successfully perturbed\n",
            "apgd-ce - 16/318 - 223 out of 256 successfully perturbed\n",
            "apgd-ce - 17/318 - 216 out of 256 successfully perturbed\n",
            "apgd-ce - 18/318 - 207 out of 256 successfully perturbed\n",
            "apgd-ce - 19/318 - 206 out of 256 successfully perturbed\n",
            "apgd-ce - 20/318 - 199 out of 256 successfully perturbed\n",
            "apgd-ce - 21/318 - 201 out of 256 successfully perturbed\n",
            "apgd-ce - 22/318 - 193 out of 256 successfully perturbed\n",
            "apgd-ce - 23/318 - 206 out of 256 successfully perturbed\n",
            "apgd-ce - 24/318 - 211 out of 256 successfully perturbed\n",
            "apgd-ce - 25/318 - 197 out of 256 successfully perturbed\n",
            "apgd-ce - 26/318 - 149 out of 256 successfully perturbed\n",
            "apgd-ce - 27/318 - 185 out of 256 successfully perturbed\n",
            "apgd-ce - 28/318 - 221 out of 256 successfully perturbed\n",
            "apgd-ce - 29/318 - 233 out of 256 successfully perturbed\n",
            "apgd-ce - 30/318 - 221 out of 256 successfully perturbed\n",
            "apgd-ce - 31/318 - 240 out of 256 successfully perturbed\n",
            "apgd-ce - 32/318 - 225 out of 256 successfully perturbed\n",
            "apgd-ce - 33/318 - 199 out of 256 successfully perturbed\n",
            "apgd-ce - 34/318 - 189 out of 256 successfully perturbed\n",
            "apgd-ce - 35/318 - 190 out of 256 successfully perturbed\n",
            "apgd-ce - 36/318 - 186 out of 256 successfully perturbed\n",
            "apgd-ce - 37/318 - 197 out of 256 successfully perturbed\n",
            "apgd-ce - 38/318 - 194 out of 256 successfully perturbed\n",
            "apgd-ce - 39/318 - 190 out of 256 successfully perturbed\n",
            "apgd-ce - 40/318 - 185 out of 256 successfully perturbed\n",
            "apgd-ce - 41/318 - 182 out of 256 successfully perturbed\n",
            "apgd-ce - 42/318 - 188 out of 256 successfully perturbed\n",
            "apgd-ce - 43/318 - 198 out of 256 successfully perturbed\n",
            "apgd-ce - 44/318 - 187 out of 256 successfully perturbed\n",
            "apgd-ce - 45/318 - 194 out of 256 successfully perturbed\n",
            "apgd-ce - 46/318 - 167 out of 256 successfully perturbed\n",
            "apgd-ce - 47/318 - 182 out of 256 successfully perturbed\n",
            "apgd-ce - 48/318 - 174 out of 256 successfully perturbed\n",
            "apgd-ce - 49/318 - 180 out of 256 successfully perturbed\n",
            "apgd-ce - 50/318 - 199 out of 256 successfully perturbed\n",
            "apgd-ce - 51/318 - 146 out of 256 successfully perturbed\n",
            "apgd-ce - 52/318 - 174 out of 256 successfully perturbed\n",
            "apgd-ce - 53/318 - 167 out of 256 successfully perturbed\n",
            "apgd-ce - 54/318 - 180 out of 256 successfully perturbed\n",
            "apgd-ce - 55/318 - 161 out of 256 successfully perturbed\n",
            "apgd-ce - 56/318 - 181 out of 256 successfully perturbed\n",
            "apgd-ce - 57/318 - 149 out of 256 successfully perturbed\n",
            "apgd-ce - 58/318 - 178 out of 256 successfully perturbed\n",
            "apgd-ce - 59/318 - 163 out of 256 successfully perturbed\n",
            "apgd-ce - 60/318 - 135 out of 256 successfully perturbed\n",
            "apgd-ce - 61/318 - 182 out of 256 successfully perturbed\n",
            "apgd-ce - 62/318 - 179 out of 256 successfully perturbed\n",
            "apgd-ce - 63/318 - 161 out of 256 successfully perturbed\n",
            "apgd-ce - 64/318 - 154 out of 256 successfully perturbed\n",
            "apgd-ce - 65/318 - 166 out of 256 successfully perturbed\n",
            "apgd-ce - 66/318 - 160 out of 256 successfully perturbed\n",
            "apgd-ce - 67/318 - 159 out of 256 successfully perturbed\n",
            "apgd-ce - 68/318 - 169 out of 256 successfully perturbed\n",
            "apgd-ce - 69/318 - 155 out of 256 successfully perturbed\n",
            "apgd-ce - 70/318 - 140 out of 256 successfully perturbed\n",
            "apgd-ce - 71/318 - 159 out of 256 successfully perturbed\n",
            "apgd-ce - 72/318 - 147 out of 256 successfully perturbed\n",
            "apgd-ce - 73/318 - 167 out of 256 successfully perturbed\n",
            "apgd-ce - 74/318 - 149 out of 256 successfully perturbed\n",
            "apgd-ce - 75/318 - 145 out of 256 successfully perturbed\n",
            "apgd-ce - 76/318 - 178 out of 256 successfully perturbed\n",
            "apgd-ce - 77/318 - 171 out of 256 successfully perturbed\n",
            "apgd-ce - 78/318 - 171 out of 256 successfully perturbed\n",
            "apgd-ce - 79/318 - 171 out of 256 successfully perturbed\n",
            "apgd-ce - 80/318 - 178 out of 256 successfully perturbed\n",
            "apgd-ce - 81/318 - 163 out of 256 successfully perturbed\n",
            "apgd-ce - 82/318 - 152 out of 256 successfully perturbed\n",
            "apgd-ce - 83/318 - 172 out of 256 successfully perturbed\n",
            "apgd-ce - 84/318 - 178 out of 256 successfully perturbed\n",
            "apgd-ce - 85/318 - 181 out of 256 successfully perturbed\n",
            "apgd-ce - 86/318 - 185 out of 256 successfully perturbed\n",
            "apgd-ce - 87/318 - 163 out of 256 successfully perturbed\n",
            "apgd-ce - 88/318 - 164 out of 256 successfully perturbed\n",
            "apgd-ce - 89/318 - 197 out of 256 successfully perturbed\n",
            "apgd-ce - 90/318 - 189 out of 256 successfully perturbed\n",
            "apgd-ce - 91/318 - 168 out of 256 successfully perturbed\n",
            "apgd-ce - 92/318 - 83 out of 256 successfully perturbed\n",
            "apgd-ce - 93/318 - 72 out of 256 successfully perturbed\n",
            "apgd-ce - 94/318 - 71 out of 256 successfully perturbed\n",
            "apgd-ce - 95/318 - 81 out of 256 successfully perturbed\n",
            "apgd-ce - 96/318 - 67 out of 256 successfully perturbed\n",
            "apgd-ce - 97/318 - 85 out of 256 successfully perturbed\n",
            "apgd-ce - 98/318 - 56 out of 256 successfully perturbed\n",
            "apgd-ce - 99/318 - 56 out of 256 successfully perturbed\n",
            "apgd-ce - 100/318 - 67 out of 256 successfully perturbed\n",
            "apgd-ce - 101/318 - 55 out of 256 successfully perturbed\n",
            "apgd-ce - 102/318 - 59 out of 256 successfully perturbed\n",
            "apgd-ce - 103/318 - 52 out of 256 successfully perturbed\n",
            "apgd-ce - 104/318 - 46 out of 256 successfully perturbed\n",
            "apgd-ce - 105/318 - 52 out of 256 successfully perturbed\n",
            "apgd-ce - 106/318 - 67 out of 256 successfully perturbed\n",
            "apgd-ce - 107/318 - 41 out of 256 successfully perturbed\n",
            "apgd-ce - 108/318 - 51 out of 256 successfully perturbed\n",
            "apgd-ce - 109/318 - 66 out of 256 successfully perturbed\n",
            "apgd-ce - 110/318 - 51 out of 256 successfully perturbed\n",
            "apgd-ce - 111/318 - 48 out of 256 successfully perturbed\n",
            "apgd-ce - 112/318 - 52 out of 256 successfully perturbed\n",
            "apgd-ce - 113/318 - 62 out of 256 successfully perturbed\n",
            "apgd-ce - 114/318 - 60 out of 256 successfully perturbed\n",
            "apgd-ce - 115/318 - 58 out of 256 successfully perturbed\n",
            "apgd-ce - 116/318 - 58 out of 256 successfully perturbed\n",
            "apgd-ce - 117/318 - 51 out of 256 successfully perturbed\n",
            "apgd-ce - 118/318 - 60 out of 256 successfully perturbed\n",
            "apgd-ce - 119/318 - 59 out of 256 successfully perturbed\n",
            "apgd-ce - 120/318 - 72 out of 256 successfully perturbed\n",
            "apgd-ce - 121/318 - 63 out of 256 successfully perturbed\n",
            "apgd-ce - 122/318 - 54 out of 256 successfully perturbed\n",
            "apgd-ce - 123/318 - 58 out of 256 successfully perturbed\n",
            "apgd-ce - 124/318 - 43 out of 256 successfully perturbed\n",
            "apgd-ce - 125/318 - 56 out of 256 successfully perturbed\n",
            "apgd-ce - 126/318 - 62 out of 256 successfully perturbed\n",
            "apgd-ce - 127/318 - 51 out of 256 successfully perturbed\n",
            "apgd-ce - 128/318 - 62 out of 256 successfully perturbed\n",
            "apgd-ce - 129/318 - 65 out of 256 successfully perturbed\n",
            "apgd-ce - 130/318 - 79 out of 256 successfully perturbed\n",
            "apgd-ce - 131/318 - 63 out of 256 successfully perturbed\n",
            "apgd-ce - 132/318 - 66 out of 256 successfully perturbed\n",
            "apgd-ce - 133/318 - 72 out of 256 successfully perturbed\n",
            "apgd-ce - 134/318 - 80 out of 256 successfully perturbed\n",
            "apgd-ce - 135/318 - 56 out of 256 successfully perturbed\n",
            "apgd-ce - 136/318 - 72 out of 256 successfully perturbed\n",
            "apgd-ce - 137/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 138/318 - 63 out of 256 successfully perturbed\n",
            "apgd-ce - 139/318 - 70 out of 256 successfully perturbed\n",
            "apgd-ce - 140/318 - 65 out of 256 successfully perturbed\n",
            "apgd-ce - 141/318 - 79 out of 256 successfully perturbed\n",
            "apgd-ce - 142/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 143/318 - 67 out of 256 successfully perturbed\n",
            "apgd-ce - 144/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 145/318 - 79 out of 256 successfully perturbed\n",
            "apgd-ce - 146/318 - 66 out of 256 successfully perturbed\n",
            "apgd-ce - 147/318 - 76 out of 256 successfully perturbed\n",
            "apgd-ce - 148/318 - 80 out of 256 successfully perturbed\n",
            "apgd-ce - 149/318 - 68 out of 256 successfully perturbed\n",
            "apgd-ce - 150/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 151/318 - 71 out of 256 successfully perturbed\n",
            "apgd-ce - 152/318 - 86 out of 256 successfully perturbed\n",
            "apgd-ce - 153/318 - 68 out of 256 successfully perturbed\n",
            "apgd-ce - 154/318 - 61 out of 256 successfully perturbed\n",
            "apgd-ce - 155/318 - 70 out of 256 successfully perturbed\n",
            "apgd-ce - 156/318 - 66 out of 256 successfully perturbed\n",
            "apgd-ce - 157/318 - 60 out of 256 successfully perturbed\n",
            "apgd-ce - 158/318 - 24 out of 256 successfully perturbed\n",
            "apgd-ce - 159/318 - 18 out of 256 successfully perturbed\n",
            "apgd-ce - 160/318 - 46 out of 256 successfully perturbed\n",
            "apgd-ce - 161/318 - 13 out of 256 successfully perturbed\n",
            "apgd-ce - 162/318 - 13 out of 256 successfully perturbed\n",
            "apgd-ce - 163/318 - 21 out of 256 successfully perturbed\n",
            "apgd-ce - 164/318 - 34 out of 256 successfully perturbed\n",
            "apgd-ce - 165/318 - 20 out of 256 successfully perturbed\n",
            "apgd-ce - 166/318 - 18 out of 256 successfully perturbed\n",
            "apgd-ce - 167/318 - 20 out of 256 successfully perturbed\n",
            "apgd-ce - 168/318 - 20 out of 256 successfully perturbed\n",
            "apgd-ce - 169/318 - 23 out of 256 successfully perturbed\n",
            "apgd-ce - 170/318 - 57 out of 256 successfully perturbed\n",
            "apgd-ce - 171/318 - 173 out of 256 successfully perturbed\n",
            "apgd-ce - 172/318 - 159 out of 256 successfully perturbed\n",
            "apgd-ce - 173/318 - 169 out of 256 successfully perturbed\n",
            "apgd-ce - 174/318 - 154 out of 256 successfully perturbed\n",
            "apgd-ce - 175/318 - 142 out of 256 successfully perturbed\n",
            "apgd-ce - 176/318 - 165 out of 256 successfully perturbed\n",
            "apgd-ce - 177/318 - 142 out of 256 successfully perturbed\n",
            "apgd-ce - 178/318 - 131 out of 256 successfully perturbed\n",
            "apgd-ce - 179/318 - 123 out of 256 successfully perturbed\n",
            "apgd-ce - 180/318 - 115 out of 256 successfully perturbed\n",
            "apgd-ce - 181/318 - 100 out of 256 successfully perturbed\n",
            "apgd-ce - 182/318 - 109 out of 256 successfully perturbed\n",
            "apgd-ce - 183/318 - 102 out of 256 successfully perturbed\n",
            "apgd-ce - 184/318 - 85 out of 256 successfully perturbed\n",
            "apgd-ce - 185/318 - 93 out of 256 successfully perturbed\n",
            "apgd-ce - 186/318 - 77 out of 256 successfully perturbed\n",
            "apgd-ce - 187/318 - 77 out of 256 successfully perturbed\n",
            "apgd-ce - 188/318 - 79 out of 256 successfully perturbed\n",
            "apgd-ce - 189/318 - 53 out of 256 successfully perturbed\n",
            "apgd-ce - 190/318 - 61 out of 256 successfully perturbed\n",
            "apgd-ce - 191/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 192/318 - 52 out of 256 successfully perturbed\n",
            "apgd-ce - 193/318 - 34 out of 256 successfully perturbed\n",
            "apgd-ce - 194/318 - 40 out of 256 successfully perturbed\n",
            "apgd-ce - 195/318 - 30 out of 256 successfully perturbed\n",
            "apgd-ce - 196/318 - 49 out of 256 successfully perturbed\n",
            "apgd-ce - 197/318 - 38 out of 256 successfully perturbed\n",
            "apgd-ce - 198/318 - 34 out of 256 successfully perturbed\n",
            "apgd-ce - 199/318 - 27 out of 256 successfully perturbed\n",
            "apgd-ce - 200/318 - 69 out of 256 successfully perturbed\n",
            "apgd-ce - 201/318 - 60 out of 256 successfully perturbed\n",
            "apgd-ce - 202/318 - 37 out of 256 successfully perturbed\n",
            "apgd-ce - 203/318 - 62 out of 256 successfully perturbed\n",
            "apgd-ce - 204/318 - 33 out of 256 successfully perturbed\n",
            "apgd-ce - 205/318 - 48 out of 256 successfully perturbed\n",
            "apgd-ce - 206/318 - 79 out of 256 successfully perturbed\n",
            "apgd-ce - 207/318 - 69 out of 256 successfully perturbed\n",
            "apgd-ce - 208/318 - 48 out of 256 successfully perturbed\n",
            "apgd-ce - 209/318 - 58 out of 256 successfully perturbed\n",
            "apgd-ce - 210/318 - 63 out of 256 successfully perturbed\n",
            "apgd-ce - 211/318 - 39 out of 256 successfully perturbed\n",
            "apgd-ce - 212/318 - 53 out of 256 successfully perturbed\n",
            "apgd-ce - 213/318 - 73 out of 256 successfully perturbed\n",
            "apgd-ce - 214/318 - 86 out of 256 successfully perturbed\n",
            "apgd-ce - 215/318 - 144 out of 256 successfully perturbed\n",
            "apgd-ce - 216/318 - 99 out of 256 successfully perturbed\n",
            "apgd-ce - 217/318 - 86 out of 256 successfully perturbed\n",
            "apgd-ce - 218/318 - 87 out of 256 successfully perturbed\n",
            "apgd-ce - 219/318 - 99 out of 256 successfully perturbed\n",
            "apgd-ce - 220/318 - 100 out of 256 successfully perturbed\n",
            "apgd-ce - 221/318 - 121 out of 256 successfully perturbed\n",
            "apgd-ce - 222/318 - 139 out of 256 successfully perturbed\n",
            "apgd-ce - 223/318 - 126 out of 256 successfully perturbed\n",
            "apgd-ce - 224/318 - 129 out of 256 successfully perturbed\n",
            "apgd-ce - 225/318 - 185 out of 256 successfully perturbed\n",
            "apgd-ce - 226/318 - 165 out of 256 successfully perturbed\n",
            "apgd-ce - 227/318 - 155 out of 256 successfully perturbed\n",
            "apgd-ce - 228/318 - 180 out of 256 successfully perturbed\n",
            "apgd-ce - 229/318 - 204 out of 256 successfully perturbed\n",
            "apgd-ce - 230/318 - 182 out of 256 successfully perturbed\n",
            "apgd-ce - 231/318 - 152 out of 256 successfully perturbed\n",
            "apgd-ce - 232/318 - 178 out of 256 successfully perturbed\n",
            "apgd-ce - 233/318 - 179 out of 256 successfully perturbed\n",
            "apgd-ce - 234/318 - 161 out of 256 successfully perturbed\n",
            "apgd-ce - 235/318 - 199 out of 256 successfully perturbed\n",
            "apgd-ce - 236/318 - 190 out of 256 successfully perturbed\n",
            "apgd-ce - 237/318 - 189 out of 256 successfully perturbed\n",
            "apgd-ce - 238/318 - 202 out of 256 successfully perturbed\n",
            "apgd-ce - 239/318 - 218 out of 256 successfully perturbed\n",
            "apgd-ce - 240/318 - 229 out of 256 successfully perturbed\n",
            "apgd-ce - 241/318 - 228 out of 256 successfully perturbed\n",
            "apgd-ce - 242/318 - 230 out of 256 successfully perturbed\n",
            "apgd-ce - 243/318 - 231 out of 256 successfully perturbed\n",
            "apgd-ce - 244/318 - 242 out of 256 successfully perturbed\n",
            "apgd-ce - 245/318 - 230 out of 256 successfully perturbed\n",
            "apgd-ce - 246/318 - 238 out of 256 successfully perturbed\n",
            "apgd-ce - 247/318 - 244 out of 256 successfully perturbed\n",
            "apgd-ce - 248/318 - 249 out of 256 successfully perturbed\n",
            "apgd-ce - 249/318 - 253 out of 256 successfully perturbed\n",
            "apgd-ce - 250/318 - 255 out of 256 successfully perturbed\n",
            "apgd-ce - 251/318 - 254 out of 256 successfully perturbed\n",
            "apgd-ce - 252/318 - 253 out of 256 successfully perturbed\n",
            "apgd-ce - 253/318 - 255 out of 256 successfully perturbed\n",
            "apgd-ce - 254/318 - 10 out of 256 successfully perturbed\n",
            "apgd-ce - 255/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 256/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 257/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 258/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 259/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 260/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 261/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 262/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 263/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 264/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 265/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 266/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 267/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 268/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 269/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 270/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 271/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 272/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 273/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 274/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 275/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 276/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 277/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 278/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 279/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 280/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 281/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 282/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 283/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 284/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 285/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 286/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 287/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 288/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 289/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 290/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 291/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 292/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 293/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 294/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 295/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 296/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 297/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 298/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 299/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 300/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 301/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 302/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 303/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 304/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 305/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 306/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 307/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 308/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 309/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 310/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 311/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 312/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 313/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 314/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 315/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 316/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 317/318 - 0 out of 256 successfully perturbed\n",
            "apgd-ce - 318/318 - 0 out of 90 successfully perturbed\n",
            "robust accuracy after APGD-CE: 59.67% (total time 72.9 s)\n",
            "max L2 perturbation: 174.44434, nan in tensor: 0, max: 444.67896, min: -1.78455\n",
            "robust accuracy: 59.67%\n",
            "{'clean_acc': 0.9868, 'robust_acc': 0.5967}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title TDSM-MVP（VIB 8–16D＋早期退出）学習【修正版】\n",
        "import torch, torch.nn as nn, torch.nn.functional as F, time\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "LATENT_D = 16\n",
        "BATCH = 512\n",
        "EPOCHS = 5\n",
        "BETA = 1e-2\n",
        "DELTA = 0.90\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(Xtr, ytr), batch_size=BATCH, shuffle=True, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "val_loader   = DataLoader(TensorDataset(Xva, yva), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "test_loader  = DataLoader(TensorDataset(Xte, yte), batch_size=BATCH, shuffle=False, num_workers=2, pin_memory=True, persistent_workers=True)\n",
        "\n",
        "class VIBNet(nn.Module):\n",
        "    def __init__(self, in_dim, z_dim, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Linear(in_dim, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU())\n",
        "        self.mu = nn.Linear(128, z_dim); self.logvar = nn.Linear(128, z_dim)\n",
        "        self.head_early = nn.Linear(z_dim, n_classes)\n",
        "        self.head_final = nn.Linear(z_dim, n_classes)\n",
        "    def reparam(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar); eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    def forward(self, x, early_threshold=None):\n",
        "        h = self.enc(x)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        logits_early = self.head_early(mu)\n",
        "        if early_threshold is not None:\n",
        "            conf = F.softmax(logits_early, dim=1).max(dim=1).values\n",
        "            use_early = conf >= early_threshold\n",
        "        else:\n",
        "            use_early = torch.zeros(x.size(0), dtype=torch.bool, device=x.device)\n",
        "        z = self.reparam(mu, logvar); logits_final = self.head_final(z)\n",
        "        return logits_early, logits_final, mu, logvar, use_early\n",
        "\n",
        "def vib_loss(logits, y, mu, logvar, beta=BETA):\n",
        "    ce = F.cross_entropy(logits, y)\n",
        "    kl = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), dim=1).mean()\n",
        "    return ce + beta * kl, ce, kl\n",
        "\n",
        "model = VIBNet(in_dim=Xtr.shape[1], z_dim=LATENT_D).to(DEVICE)\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
        "# ★ GradScaler は amp_scaler という別名にする（前処理の StandardScaler と衝突させない）\n",
        "amp_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "\n",
        "def evaluate(loader, use_early=True):\n",
        "    model.eval(); all_p, all_y = [], []\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
        "        for xb, yb in loader:\n",
        "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "            le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA if use_early else None)\n",
        "            logits = torch.where(use_e.unsqueeze(1), le, lf)\n",
        "            prob1 = F.softmax(logits, dim=1)[:,1]\n",
        "            all_p.append(prob1.detach().cpu()); all_y.append(yb.cpu())\n",
        "    p = torch.cat(all_p).numpy(); y = torch.cat(all_y).numpy()\n",
        "    from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "    return float(roc_auc_score(y, p)), float(average_precision_score(y, p))\n",
        "\n",
        "best = -1.0\n",
        "for ep in range(1, EPOCHS+1):\n",
        "    model.train(); t0=time.time()\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.amp.autocast(device_type=\"cuda\", enabled=(DEVICE==\"cuda\"), dtype=torch.float16):\n",
        "            le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA)\n",
        "            loss, ce, kl = vib_loss(lf, yb, mu, logvar, beta=BETA)\n",
        "        amp_scaler.scale(loss).backward()\n",
        "        amp_scaler.step(opt); amp_scaler.update()\n",
        "    val_roc, val_ap = evaluate(val_loader, use_early=True)\n",
        "    print(f\"[EP{ep}] val AUROC={val_roc:.4f} AP={val_ap:.4f} | time={time.time()-t0:.1f}s\")\n",
        "    if val_roc > best:\n",
        "        best = val_roc\n",
        "        import os\n",
        "        torch.save(model.state_dict(), os.path.join(DRIVE_DIR, \"artifacts\", \"vib_best.pt\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXe9aeUsML5H",
        "outputId": "83754f7c-8f04-4d32-982d-4bdb4d94565d"
      },
      "id": "yXe9aeUsML5H",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1954849698.py:46: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  amp_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[EP1] val AUROC=0.9868 AP=0.9874 | time=2.3s\n",
            "[EP2] val AUROC=0.9935 AP=0.9944 | time=1.1s\n",
            "[EP3] val AUROC=0.9969 AP=0.9971 | time=1.1s\n",
            "[EP4] val AUROC=0.9976 AP=0.9977 | time=1.1s\n",
            "[EP5] val AUROC=0.9973 AP=0.9971 | time=1.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cf87af9-20ec-43f3-9b55-025a1f0c606d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6730e4a-2242-4002-c868-99d64c969b89"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: ['vib_best.pt', 'scaler.pkl']\n"
          ]
        }
      ],
      "source": [
        "#@title 成果物の保存\n",
        "import joblib, json, os, torch\n",
        "joblib.dump(scaler, os.path.join(DRIVE_DIR, \"artifacts\", \"scaler.pkl\"))\n",
        "torch.save(model.state_dict(), os.path.join(DRIVE_DIR, \"artifacts\", \"vib_best.pt\"))\n",
        "conf = dict(seed=int(SEED), latent=int(LATENT_D), beta=float(BETA), delta=float(DELTA), features=len(feature_cols),\n",
        "            data_paths=DATA_PATHS)\n",
        "import json\n",
        "json.dump(conf, open(os.path.join(DRIVE_DIR, \"configs\", \"run.json\"), \"w\"), indent=2, ensure_ascii=False)\n",
        "print(\"Saved:\", os.listdir(os.path.join(DRIVE_DIR,\"artifacts\")))"
      ],
      "id": "6cf87af9-20ec-43f3-9b55-025a1f0c606d"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🔁 フル自己完結：自動レポート生成セル（セットアップ込み）\n",
        "import os, json, time, datetime, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "\n",
        "# ================= ユーザ設定（必要なら変更） =================\n",
        "PROJ_DIR_DEFAULT = \"/content/drive/MyDrive/tdsm_v2\"\n",
        "N_BINS = 15\n",
        "THRESH_GRID = np.linspace(0.01, 0.99, 99)\n",
        "EPS_LIST = [0.05, 0.10, 0.15, 0.20, 0.25]  # AutoAttack L2\n",
        "AA_ITERS = 100\n",
        "AA_RESTARTS = 1\n",
        "RUN_EPS_SWEEP = True\n",
        "# =========================================================\n",
        "\n",
        "# ---- Colab Drive を未マウントならマウント ----\n",
        "try:\n",
        "    from google.colab import drive  # noqa\n",
        "    need_mount = not os.path.isdir(\"/content/drive/MyDrive\")\n",
        "    if need_mount:\n",
        "        drive.mount(\"/content/drive\")\n",
        "except Exception:\n",
        "    pass  # Colab以外\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "PROJ_DIR = PROJ_DIR_DEFAULT\n",
        "os.makedirs(PROJ_DIR, exist_ok=True)\n",
        "CFG_DIR  = os.path.join(PROJ_DIR, \"configs\")\n",
        "ART_DIR  = os.path.join(PROJ_DIR, \"artifacts\")\n",
        "DATA_DIR = os.path.join(PROJ_DIR, \"data\")\n",
        "os.makedirs(CFG_DIR, exist_ok=True); os.makedirs(ART_DIR, exist_ok=True); os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "stamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "REPORT_DIR = os.path.join(PROJ_DIR, \"reports\", stamp)\n",
        "os.makedirs(REPORT_DIR, exist_ok=True)\n",
        "print(\"REPORT_DIR:\", REPORT_DIR)\n",
        "\n",
        "# ---- DATA_PATHS を読み込み or 推定 ----\n",
        "def load_json_if(p):\n",
        "    return json.load(open(p)) if os.path.isfile(p) else None\n",
        "\n",
        "DATA_PATHS = load_json_if(os.path.join(CFG_DIR, \"DATA_PATHS.json\")) or \\\n",
        "             load_json_if(os.path.join(CFG_DIR, \"DATA_PATHS_detected.json\"))\n",
        "\n",
        "if not DATA_PATHS:\n",
        "    # よくある配置から推測（UNSWの自動分割名を優先）\n",
        "    cand_test = [\n",
        "        os.path.join(DATA_DIR, \"UNSW_NB15_testing-set.csv\"),\n",
        "        \"/content/drive/MyDrive/UNSW_NB15_testing-set.csv\"\n",
        "    ]\n",
        "    test_p = next((p for p in cand_test if os.path.isfile(p)), None)\n",
        "    DATA_PATHS = {\n",
        "        \"train\": os.path.join(DATA_DIR, \"auto_train_from_UNSWtest.csv\") if os.path.isfile(os.path.join(DATA_DIR,\"auto_train_from_UNSWtest.csv\")) else None,\n",
        "        \"val\":   os.path.join(DATA_DIR, \"auto_val_from_UNSWtest.csv\")   if os.path.isfile(os.path.join(DATA_DIR,\"auto_val_from_UNSWtest.csv\")) else None,\n",
        "        \"test\":  test_p\n",
        "    }\n",
        "print(\"DATA_PATHS:\", DATA_PATHS)\n",
        "\n",
        "# ---- データ読み込み（数値列のみ）＆ label 整備 ----\n",
        "def load_df(path):\n",
        "    if path is None: return None\n",
        "    return pd.read_parquet(path) if path.lower().endswith(\".parquet\") else pd.read_csv(path)\n",
        "\n",
        "def ensure_label(df):\n",
        "    if df is None: return None\n",
        "    for cand in [\"label\",\"Label\",\"class\",\"Class\",\"target\",\"Target\",\"y\"]:\n",
        "        if cand in df.columns:\n",
        "            if cand != \"label\":\n",
        "                df[\"label\"] = df[cand].astype(\"int64\")\n",
        "            return df\n",
        "    if \"attack_cat\" in df.columns:\n",
        "        df[\"label\"] = (df[\"attack_cat\"].astype(str).str.lower()!=\"normal\").astype(\"int64\")\n",
        "        return df\n",
        "    raise ValueError(\"ラベル列が見つかりません（label/class/attack_cat等）\")\n",
        "\n",
        "df_train = ensure_label(load_df(DATA_PATHS.get(\"train\")))\n",
        "df_val   = ensure_label(load_df(DATA_PATHS.get(\"val\")))\n",
        "df_test  = ensure_label(load_df(DATA_PATHS.get(\"test\")))\n",
        "assert df_test is not None, \"test データが見つかりません。\"\n",
        "\n",
        "def pick_numeric_cols(df):\n",
        "    import numpy as np\n",
        "    return [c for c in df.select_dtypes(include=[np.number]).columns if c!=\"label\"]\n",
        "\n",
        "feature_cols = pick_numeric_cols(df_train if df_train is not None else df_test)\n",
        "print(\"Feature dim:\", len(feature_cols))\n",
        "\n",
        "# ---- スケーラ（artifacts/scaler.pkl を優先）----\n",
        "import joblib\n",
        "scaler_path = os.path.join(ART_DIR, \"scaler.pkl\")\n",
        "if os.path.isfile(scaler_path):\n",
        "    scaler = joblib.load(scaler_path)\n",
        "else:\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    fit_df = df_train if df_train is not None else df_test\n",
        "    scaler = StandardScaler().fit(fit_df[feature_cols].values)\n",
        "    joblib.dump(scaler, scaler_path)\n",
        "\n",
        "def to_tensors(df):\n",
        "    X = scaler.transform(df[feature_cols].values).astype(\"float32\")\n",
        "    y = df[\"label\"].astype(\"int64\").values\n",
        "    return torch.tensor(X), torch.tensor(y)\n",
        "\n",
        "Xtr, ytr = (to_tensors(df_train) if df_train is not None else (None, None))\n",
        "Xva, yva = (to_tensors(df_val)   if df_val   is not None else (None, None))\n",
        "Xte, yte = to_tensors(df_test)\n",
        "\n",
        "# ---- モデル定義＆ロード（VIBNet）----\n",
        "class VIBNet(nn.Module):\n",
        "    def __init__(self, in_dim, z_dim=16, n_classes=2):\n",
        "        super().__init__()\n",
        "        self.enc = nn.Sequential(nn.Linear(in_dim, 256), nn.ReLU(), nn.Linear(256, 128), nn.ReLU())\n",
        "        self.mu = nn.Linear(128, z_dim); self.logvar = nn.Linear(128, z_dim)\n",
        "        self.head_early = nn.Linear(z_dim, n_classes)\n",
        "        self.head_final = nn.Linear(z_dim, n_classes)\n",
        "    def reparam(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar); eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "    def logits_det(self, x):  # 決定論：μ→early head\n",
        "        h  = self.enc(x); mu = self.mu(h); return self.head_early(mu)\n",
        "    def forward(self, x, early_threshold=None):\n",
        "        h = self.enc(x)\n",
        "        mu, logvar = self.mu(h), self.logvar(h)\n",
        "        logits_early = self.head_early(mu)\n",
        "        use_early = torch.zeros(x.size(0), dtype=torch.bool, device=x.device) if early_threshold is None \\\n",
        "                    else (F.softmax(logits_early, dim=1).max(dim=1).values >= early_threshold)\n",
        "        z = self.reparam(mu, logvar); logits_final = self.head_final(z)\n",
        "        return logits_early, logits_final, mu, logvar, use_early\n",
        "\n",
        "# latent の既定値（run.json があれば拾う）\n",
        "LATENT_D = 16\n",
        "cfg_path = os.path.join(CFG_DIR, \"run.json\")\n",
        "if os.path.isfile(cfg_path):\n",
        "    try:\n",
        "        cfg = json.load(open(cfg_path))\n",
        "        LATENT_D = int(cfg.get(\"latent\", LATENT_D))\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "model = VIBNet(in_dim=len(feature_cols), z_dim=LATENT_D).to(DEVICE)\n",
        "ckpt = os.path.join(ART_DIR, \"vib_best.pt\")\n",
        "assert os.path.isfile(ckpt), f\"モデル重みが見つかりません: {ckpt}\"\n",
        "model.load_state_dict(torch.load(ckpt, map_stage=DEVICE) if hasattr(torch, \"load\") else torch.load(ckpt, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "# ---- 基本メトリクス（metrics.json が無ければ test だけでも作る）----\n",
        "from sklearn.metrics import (precision_recall_fscore_support, accuracy_score,\n",
        "                             roc_auc_score, average_precision_score,\n",
        "                             roc_curve, precision_recall_curve, confusion_matrix)\n",
        "\n",
        "def eval_split_logits(X, y, name=\"split\", thr=0.5):\n",
        "    with torch.no_grad():\n",
        "        logits = model.logits_det(X.to(DEVICE))\n",
        "        proba1 = torch.softmax(logits,1)[:,1].cpu().numpy()\n",
        "    yt = y.numpy()\n",
        "    yhat = (proba1 >= thr).astype(int)\n",
        "    pr, rc, f1, _ = precision_recall_fscore_support(yt, yhat, average=\"binary\", zero_division=0)\n",
        "    acc = accuracy_score(yt, yhat)\n",
        "    roc = roc_auc_score(yt, proba1)\n",
        "    ap  = average_precision_score(yt, proba1)\n",
        "    cm  = confusion_matrix(yt, yhat)\n",
        "    return {\"name\": name, \"acc\": float(acc), \"precision\": float(pr), \"recall\": float(rc),\n",
        "            \"f1\": float(f1), \"auroc\": float(roc), \"auprc\": float(ap), \"cm\": cm.tolist(),\n",
        "            \"proba\": proba1, \"y_true\": yt}\n",
        "\n",
        "metrics = []\n",
        "if Xtr is not None: metrics.append(eval_split_logits(Xtr, ytr, \"train\"))\n",
        "if Xva is not None: metrics.append(eval_split_logits(Xva, yva, \"val\"))\n",
        "metrics.append(eval_split_logits(Xte, yte, \"test\"))\n",
        "\n",
        "# 保存（pred_*.csv & metrics.json）\n",
        "for m in metrics:\n",
        "    pd.DataFrame({\"y_true\": m[\"y_true\"], \"proba1\": m[\"proba\"]}).to_csv(os.path.join(REPORT_DIR, f\"pred_{m['name']}.csv\"), index=False)\n",
        "json.dump([{k:v for k,v in m.items() if k not in (\"proba\",\"y_true\")} for m in metrics],\n",
        "          open(os.path.join(REPORT_DIR, \"metrics.json\"), \"w\"), indent=2)\n",
        "\n",
        "# ---- ここから自動レポート生成（ROC/PR, しきい値, ECE, εスイープ）----\n",
        "y_true = metrics[-1][\"y_true\"]; proba = metrics[-1][\"proba\"]\n",
        "\n",
        "# ROC/PR\n",
        "fpr, tpr, _ = roc_curve(y_true, proba)\n",
        "prec, rec, _ = precision_recall_curve(y_true, proba)\n",
        "plt.figure(figsize=(4.5,4)); plt.plot(fpr,tpr); plt.plot([0,1],[0,1],'--'); plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(\"ROC (test)\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(REPORT_DIR,\"roc_test.png\"), dpi=150); plt.show()\n",
        "plt.figure(figsize=(4.5,4)); plt.plot(rec,prec); plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(\"PR (test)\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(REPORT_DIR,\"pr_test.png\"), dpi=150); plt.show()\n",
        "\n",
        "# しきい値スイープ（F1最大）\n",
        "def metrics_at_threshold(y, p, thr):\n",
        "    yhat = (p >= thr).astype(int)\n",
        "    pr, rc, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
        "    acc = accuracy_score(y, yhat)\n",
        "    roc = roc_auc_score(y, p)\n",
        "    ap  = average_precision_score(y, p)\n",
        "    cm  = confusion_matrix(y, yhat)\n",
        "    return dict(threshold=float(thr), acc=float(acc), precision=float(pr), recall=float(rc),\n",
        "                f1=float(f1), auroc=float(roc), auprc=float(ap), cm=cm.tolist())\n",
        "\n",
        "curves = [metrics_at_threshold(y_true, proba, t) for t in THRESH_GRID]\n",
        "best = max(curves, key=lambda d: d[\"f1\"])\n",
        "plt.figure(figsize=(5,3.5))\n",
        "plt.plot([c[\"threshold\"] for c in curves], [c[\"f1\"] for c in curves], label=\"F1\")\n",
        "plt.plot([c[\"threshold\"] for c in curves], [c[\"precision\"] for c in curves], label=\"Precision\", alpha=0.7)\n",
        "plt.plot([c[\"threshold\"] for c in curves], [c[\"recall\"] for c in curves], label=\"Recall\",   alpha=0.7)\n",
        "plt.axvline(best[\"threshold\"], ls=\"--\", label=f\"best={best['threshold']:.2f}\")\n",
        "plt.legend(); plt.xlabel(\"Threshold\"); plt.ylabel(\"Score\"); plt.title(\"Threshold sweep (test)\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(REPORT_DIR,\"threshold_sweep.png\"), dpi=150); plt.show()\n",
        "json.dump({\"best\": best, \"curve\": curves}, open(os.path.join(REPORT_DIR,\"thresholds.json\"),\"w\"), indent=2)\n",
        "\n",
        "# 校正（ECE; 分位ビニング）\n",
        "def ece_quantile(y, p, n_bins=15):\n",
        "    qs = np.unique(np.quantile(p, np.linspace(0,1,n_bins+1)))\n",
        "    if len(qs) < 3: qs = np.linspace(0,1,n_bins+1)\n",
        "    idx = np.digitize(p, qs[1:-1], right=True)\n",
        "    ece=0.0; xs=[]; ys=[]; bins=[]\n",
        "    for b in range(len(qs)-1):\n",
        "        mask = (idx==b)\n",
        "        if not np.any(mask):\n",
        "            bins.append(dict(bin=b, size=0)); continue\n",
        "        conf = p[mask].mean(); acc = (y[mask]==(p[mask]>=0.5)).mean(); w = mask.mean()\n",
        "        ece += w*abs(acc-conf)\n",
        "        xs.append(conf); ys.append(acc)\n",
        "        bins.append(dict(bin=b, lower=float(qs[b]), upper=float(qs[b+1]), size=int(mask.sum()),\n",
        "                         conf=float(conf), acc=float(acc), weight=float(w)))\n",
        "    return float(ece), xs, ys, bins, qs.tolist()\n",
        "\n",
        "ece, xs, ys, bins, qs = ece_quantile(y_true, proba, n_bins=N_BINS)\n",
        "plt.figure(figsize=(4.5,4)); plt.plot([0,1],[0,1],'--', lw=1); plt.scatter(xs, ys, s=25)\n",
        "plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Empirical positive rate\")\n",
        "plt.title(f\"Reliability diagram (test) | ECE={ece:.3f}\")\n",
        "plt.tight_layout(); plt.savefig(os.path.join(REPORT_DIR,\"calibration_test.png\"), dpi=150); plt.show()\n",
        "json.dump({\"n_bins\": N_BINS, \"ece\": ece, \"quantiles\": qs, \"bins\": bins},\n",
        "          open(os.path.join(REPORT_DIR, \"ece.json\"), \"w\"), indent=2)\n",
        "\n",
        "# 早期退出率（DELTAは run.json があれば使用）\n",
        "DELTA = 0.90\n",
        "if os.path.isfile(cfg_path):\n",
        "    try:\n",
        "        cfg = json.load(open(cfg_path)); DELTA = float(cfg.get(\"delta\", DELTA))\n",
        "    except Exception: pass\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "test_loader = DataLoader(TensorDataset(Xte, yte), batch_size=512, shuffle=False)\n",
        "use_early_all = []\n",
        "with torch.no_grad():\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(DEVICE)\n",
        "        le, lf, mu, logvar, use_e = model(xb, early_threshold=DELTA)\n",
        "        use_early_all.append(use_e.cpu())\n",
        "ee_ratio = float(torch.cat(use_early_all).float().mean().item())\n",
        "json.dump({\"delta\": DELTA, \"early_ratio_test\": ee_ratio}, open(os.path.join(REPORT_DIR,\"early_exit.json\"),\"w\"), indent=2)\n",
        "\n",
        "# εスイープ（APGD-CE; tabular/2値）\n",
        "rob_curve = []\n",
        "if RUN_EPS_SWEEP:\n",
        "    try:\n",
        "        from autoattack import AutoAttack\n",
        "        class DetWrapper(nn.Module):\n",
        "            def __init__(self, mdl): super().__init__(); self.mdl = mdl\n",
        "            def forward(self, x): return self.mdl.logits_det(x)\n",
        "        wrp = DetWrapper(model).to(DEVICE).eval()\n",
        "        Xaa, yaa = Xte.to(DEVICE), yte.to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            clean_acc = (torch.softmax(wrp(Xaa),1).argmax(1)==yaa).float().mean().item()\n",
        "        for eps in EPS_LIST:\n",
        "            aa = AutoAttack(wrp, norm='L2', eps=eps, version='custom')\n",
        "            aa.attacks_to_run = ['apgd-ce']\n",
        "            aa.apgd.n_iter = AA_ITERS; aa.apgd.n_restarts = AA_RESTARTS\n",
        "            x_adv = aa.run_standard_evaluation(Xaa, yaa, bs=256)\n",
        "            with torch.no_grad():\n",
        "                rob = (torch.softmax(wrp(x_adv),1).argmax(1)==yaa).float().mean().item()\n",
        "            rob_curve.append({\"eps_L2\": float(eps), \"robust_acc\": float(rob)})\n",
        "        json.dump({\"clean_acc\": float(clean_acc), \"curve\": rob_curve,\n",
        "                   \"iters\": AA_ITERS, \"restarts\": AA_RESTARTS},\n",
        "                  open(os.path.join(REPORT_DIR,\"robust_curve.json\"),\"w\"), indent=2)\n",
        "        plt.figure(figsize=(4.5,4)); plt.plot([d[\"eps_L2\"] for d in rob_curve],\n",
        "                                              [d[\"robust_acc\"] for d in rob_curve], marker=\"o\")\n",
        "        plt.xlabel(\"L2 epsilon\"); plt.ylabel(\"Robust accuracy\"); plt.title(\"AutoAttack APGD-CE (test)\")\n",
        "        plt.tight_layout(); plt.savefig(os.path.join(REPORT_DIR,\"robust_curve.png\"), dpi=150); plt.show()\n",
        "    except Exception as e:\n",
        "        print(\"AutoAttack（εスイープ）をスキップ:\", e)\n",
        "\n",
        "# Markdown レポート\n",
        "def fmt(v): return f\"{v:.4f}\" if isinstance(v, float) else str(v)\n",
        "metrics_list = json.load(open(os.path.join(REPORT_DIR, \"metrics.json\")))\n",
        "lines = [\"# TDSM v2 — AUTO REPORT\", \"\"]\n",
        "lines.append(\"## 1. Overall metrics\")\n",
        "for m in metrics_list:\n",
        "    lines.append(f\"### {m['name']}\")\n",
        "    lines.append(f\"- Acc={fmt(m['acc'])} | Precision={fmt(m['precision'])} | Recall={fmt(m['recall'])} | F1={fmt(m['f1'])}\")\n",
        "    lines.append(f\"- AUROC={fmt(m['auroc'])} | AUPRC={fmt(m['auprc'])}\")\n",
        "    lines.append(f\"- Confusion={m['cm']}\")\n",
        "    lines.append(\"\")\n",
        "lines.append(\"## 2. Threshold optimization (test)\")\n",
        "lines.append(f\"- Best threshold (max F1): **{best['threshold']:.2f}**\")\n",
        "lines.append(f\"- At best thr: Acc={fmt(best['acc'])} | P={fmt(best['precision'])} | R={fmt(best['recall'])} | F1={fmt(best['f1'])}\")\n",
        "lines.append(f\"- AUROC={fmt(best['auroc'])} | AUPRC={fmt(best['auprc'])}\")\n",
        "lines.append(\"- Figures: `threshold_sweep.png`, `roc_test.png`, `pr_test.png`\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"## 3. Calibration\")\n",
        "lines.append(f\"- ECE (quantile {N_BINS} bins): **{ece:.3f}**\")\n",
        "lines.append(\"- Figure: `calibration_test.png`\")\n",
        "lines.append(\"\")\n",
        "lines.append(\"## 4. Early-Exit\")\n",
        "lines.append(f\"- delta={DELTA}, early_ratio_test={ee_ratio:.3f}\")\n",
        "lines.append(\"\")\n",
        "rc_path = os.path.join(REPORT_DIR, \"robust_curve.json\")\n",
        "if os.path.isfile(rc_path):\n",
        "    aa = json.load(open(rc_path))\n",
        "    lines.append(\"## 5. Robustness (AutoAttack APGD-CE, L2)\")\n",
        "    lines.append(f\"- clean_acc={aa['clean_acc']:.3f}\")\n",
        "    for d in aa[\"curve\"]:\n",
        "        lines.append(f\"  - eps={d['eps_L2']:.2f} → robust_acc={d['robust_acc']:.3f}\")\n",
        "    lines.append(\"- Figure: `robust_curve.png`\")\n",
        "    lines.append(\"\")\n",
        "\n",
        "auto_md = os.path.join(REPORT_DIR, \"REPORT_AUTO.md\")\n",
        "with open(auto_md, \"w\") as f:\n",
        "    f.write(\"\\n\".join(lines))\n",
        "\n",
        "print(\"\\n✅ Auto report written to:\", auto_md)\n",
        "print(\"📁 Folder:\", REPORT_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "E5blHZMYRJ9i",
        "outputId": "a415c066-dafe-4cc3-d407-9e226e1802cf"
      },
      "id": "E5blHZMYRJ9i",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "REPORT_DIR: /content/drive/MyDrive/tdsm_v2/reports/20250830_183656\n",
            "DATA_PATHS: {'train': None, 'val': None, 'test': '/content/drive/MyDrive/UNSW_NB15_testing-set.csv'}\n",
            "Feature dim: 40\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'GradScaler' object has no attribute 'transform'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-151517048.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0mXtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mXva\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myva\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdf_val\u001b[0m   \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mXte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# ---- モデル定義＆ロード（VIBNet）----\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-151517048.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"int64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'GradScaler' object has no attribute 'transform'"
          ]
        }
      ]
    }
  ]
}